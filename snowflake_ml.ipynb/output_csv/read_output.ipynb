{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MERGED_DATA = pd.read_csv('MERGED_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_merged = pd.read_csv('MERGED_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop(columns=['ISSUING_ORGANIZATION','ISSUE_DATE',\n",
    "       'EXPIRE_DATE', 'CREDENTIAL_ID','EMAIL', 'USERTYPE', 'DATE_OF_BIRTH', 'GENDER', 'PHONENO',\n",
    "       'ADDRESS','TOTAL_CAPACITY', 'START_DATE', 'END_DATE',\n",
    "       'TRAINEE_NAME', 'MODE', 'MEETING_LINK', 'VENUE', 'USER_EMAIL','STATUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv('MERGED_DATA.csv')\n",
    "\n",
    "# Count the number of users based on rating\n",
    "rating_counts = data['RATING'].value_counts()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "rating_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of Users Based on Rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data from CSV into a DataFrame\n",
    "df = pd.read_csv('MERGED_DATA.csv')\n",
    "\n",
    "# Group the data by 'CERTIFICATE_STATUS' and count the number of employees for each status\n",
    "status_counts = df.groupby('CERTIFICATE_STATUS').size()\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "status_counts.plot(kind='bar', color=['green', 'yellow', 'red'])\n",
    "plt.title('Total Employee Count by Certificate Status')\n",
    "plt.xlabel('Certificate Status')\n",
    "plt.ylabel('Employee Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merged.iloc[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Load the data\n",
    "# df = pd.read_csv('MERGED_DATA.csv')\n",
    "\n",
    "# # Fill all null values with empty strings\n",
    "# df = df.fillna('')\n",
    "\n",
    "# # Concatenate skills and tech stacks into a single column\n",
    "# df['SKILLS_AND_TECHSTACK'] = df['SKILLS'] + ' ' + df['TECHSTACK_USED']\n",
    "\n",
    "# # Fit TF-IDF vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(df['SKILLS_AND_TECHSTACK'])\n",
    "\n",
    "# # Calculate cosine similarity\n",
    "# cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# # Function to recommend training based on employee ID\n",
    "# def recommend_training(employee_id, cosine_sim=cosine_sim, df=df):\n",
    "#     idx = df[df['EMPLOYEE_ID'] == employee_id].index[0]\n",
    "#     sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "#     sim_scores = sim_scores[1:6]  # Top 5 similar users\n",
    "#     similar_users = [i[0] for i in sim_scores]\n",
    "#     recommendations = df.iloc[similar_users]['CERTIFICATE_NAME'].unique()\n",
    "#     return recommendations\n",
    "\n",
    "# # Iterate over each employee and print unique recommendations\n",
    "\n",
    "# recommendations = recommend_training('EMP146')\n",
    "# print(\"Employee ID:\",'EMP4')\n",
    "# for certificate_name in recommendations:\n",
    "#     print(\"  -\", certificate_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Read the data\n",
    "df_merged = pd.read_csv('MERGED_DATA.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "df_merged['HAS_SKILLS_CERT_TECH'] = ((df_merged['SKILLS'].notnull()) | \n",
    "                                     (df_merged['CERTIFICATE_NAME'].notnull()) | \n",
    "                                     (df_merged['TECHSTACK_USED'].notnull())).astype(int)\n",
    "\n",
    "# Additional feature: Total experience\n",
    "df_merged['TOTAL_EXPERIENCE'] = pd.to_datetime(df_merged['END_DATE']) - pd.to_datetime(df_merged['START_DATE'])\n",
    "df_merged['TOTAL_EXPERIENCE'] = df_merged['TOTAL_EXPERIENCE'].dt.days\n",
    "\n",
    "# Define features and target variable\n",
    "X = df_merged[['HAS_SKILLS_CERT_TECH', 'RATING', 'TOTAL_EXPERIENCE']]\n",
    "y = df_merged['EVENT_NAME']\n",
    "\n",
    "# Drop rows with missing target values\n",
    "X = X[~y.isnull()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_log_reg_model = grid_search.best_estimator_\n",
    "\n",
    "def recommend_events_for_employee(employee_id):\n",
    "    employee_data = df_merged[df_merged['EMPLOYEE_ID'] == employee_id]\n",
    "    if employee_data.empty:\n",
    "        return \"No events recommended\"\n",
    "    \n",
    "    # Extract features for prediction\n",
    "    features = employee_data[['HAS_SKILLS_CERT_TECH', 'RATING', 'TOTAL_EXPERIENCE']]\n",
    "    \n",
    "    # Impute missing values with mean\n",
    "    features_imputed = imputer.transform(features)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features_imputed)\n",
    "    \n",
    "    # Predict probabilities for each class\n",
    "    event_probabilities = best_log_reg_model.predict_proba(features_scaled)\n",
    "    \n",
    "    # Get the class labels\n",
    "    class_labels = best_log_reg_model.classes_\n",
    "    \n",
    "    # Get the top recommended events\n",
    "    top_event_indices = event_probabilities.argsort()[0][-5:][::-1]  # Get top 5 recommended events\n",
    "    recommended_events = [class_labels[i] for i in top_event_indices]\n",
    "    \n",
    "    return recommended_events\n",
    "\n",
    "# Example usage:\n",
    "employee_id = \"EMP123\"  # Replace with the desired employee ID\n",
    "recommended_events = recommend_events_for_employee(employee_id)\n",
    "print(\"Recommended events for employee\", employee_id, \":\", recommended_events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Exclude non-numeric columns\n",
    "# numeric_df = df_merged.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# # Compute correlation matrix\n",
    "# correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# # Set up the matplotlib figure\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "# # Plot the heatmap\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "# # Add title and display the plot\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
